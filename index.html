<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Contexual-Gesture: Co-Speech Gesture Video Generation Through Context-aware Gesture Representation.">
  <meta name="keywords" content="gesture generation, motion representation, video generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Intent-Aware Co-Speech Gesture Generation via Semantic-Emotional Disentanglement and Alignment</h1>

<div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Arxiv PDF link -->
                            <span class="link-block">
                        <a href="..." target="_blank"
                           class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                            <!-- Github link -->
                            <span class="link-block">
                    <a href="..." target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code coming soon!</span>
                  </a>
                </span>

                            <!-- ArXiv abstract Link -->
                            <span class="link-block">
                  <a href="..." target="_blank"
                     class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                        </div>
                    </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Co-speech gesture generation aims to synthesize 3D human motions that are semantically consistent and rhythmically aligned with input speech. While recent diffusion-based approaches have significantly improved motion quality and diversity, most existing methods fail to explicitly model the emotional cues embedded in speech or effectively disentangle semantic content from emotional style. This entanglement often leads to generated gestures that lack expressiveness or suffer from semantic ambiguity when emotional controls are applied. To address these limitations, this paper proposes the Intent-Aware Co-Speech Gesture (IACG) framework, which features Semantic-Emotional Disentanglement and Alignment. First, we introduce a dual-stream architecture that disentangles speech into independent semantic and emotional subspaces using a novel cross-reconstruction training strategy, which penalizes the mutual information between the semantic and emotional features in the latent space by forcing one stream's representation to fail in reconstructing the other stream's input. Second, to capture the intrinsic coupling between semantic and emotional, we design a Bimodal Intent Alignment mechanism that adaptively fuses these decoupled features through bidirectional interaction, forming a unified generation intent, i.e., a structured latent condition that explicitly preserves semantic invariance while modulating emotional intensity. Finally, this intent serves as the condition for a Latent Diffusion Model (LDM) equipped with a discrete motion prior (VQ-VAE), where a specialized intent alignment loss ensures the synthesized motions remain faithful to both linguistic meaning and emotional intensity. Extensive experiments on the BEAT2 and TED Emotion datasets demonstrate that our method outperforms state-of-the-art approaches in terms of motion quality, semantic consistency, and emotional controllability.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3" style="text-align: center;">Method</h2>
     <center><div class="hero-body">
        <img src="static/image/pipeline.png"/>
      <p>Overview of the proposed IACG framework. The architecture comprises three stages: (i) Dual-Stream Disentanglement: Extracts independent semantic $z_s$ and emotional $z_e$ features using frozen encoders (indicated by \textcolor{blue}{snowflakes}).
(ii) Bimodal Intent Alignment: Fuses these features into a unified intent condition $z_{fuse}$.
(iii) Latent Diffusion Generation: Synthesizes motion latents conditioned on $z_{fuse}$, utilizing a VQ-VAE motion prior (bottom left). The stop-gradient $sg[\cdot]$ ensures decoupled training of the prior and diffusion model, while \textcolor{red}{flame} icons indicate trainable modules.</p>
    </div> </center>
<!--         <center><div class="hero-body">
        <img src="static/image/csta.png"/>
      <p>The CSTA module. The module consists of three key components: spatio-temporal feature decomposition, hierarchical attention computation, and dynamic gated fusion. These components collaboratively process the extracted speech features to achieve precise motion synthesis.</p>
    </div></center> -->
<!--     <div class="hero-body"> -->
<!--         <img src="static/image/stage2.png"/> -->
<!--       <p>Overview of the second stage of our framework. The inputs include Gaussian noise, keypoint sequences, the target person's image, and the pretrained HMM module (upper left). These inputs are processed through a hierarchical diffusion model, where the HMM module injects memory features to enhance motion coherence. Finally, the VAE decoder generates the video sequence with anatomically consistent gestures and smooth temporal dynamics.</p> -->
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">  
      <div class="columns is-centered has-text-centered">
        <div class="column">
          
          <h2 class="title is-3">Results</h2>
          
          <div class="content">
            <!-- ==================== 第一行视频 ==================== -->
            <div class="columns is-centered">
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/2_scott_0_103_103.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/2_scott_0_87_87.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/3_solomon_0_65_65.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/idsg_solomon_0_111_111.mp4" type="video/mp4">
                </video>
              </div>
            </div>
            
            <!-- ==================== 第二行视频 ==================== -->
            <div class="columns is-centered">
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/6_carla_0_73_73.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/6_carla_0_95_95.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/7_sophie_0_73_73.mp4" type="video/mp4">
                </video>
              </div>
              <div class="column is-one-fourth has-text-centered">

                <video poster="" playsinline autoplay muted loop controls style="width: 100%; max-width: 400px;">
                  <source src="static/results/7_sophie_0_81_81.mp4" type="video/mp4">
                </video>
              </div>
            </div>
          </div>

          <p class="content has-text-centered">
             The experimental results of our proposed model. The videos showcase how our approach produces realistic and consistent co-speech gestures, with smooth upper-body movements and expressive hand dynamics, aligned with the corresponding speech input.
          </p>
          
        </div>
      </div>    
    </div>
  </div>
</section>

  
<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <h2 class="title is-4">Comparison on PATS</h2>
      
      <div id="results-carousel" class="carousel results-carousel" style="height: 600px; margin: auto;">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/contrast/1_1_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/contrast/2_2_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <source src="static/contrast/3_3_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">
            <source src="static/contrast/4_4_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
      <h2 class="content has-text-centered">
        Qualitative results compared with other methods. Our method achieves accurate gesture generation and high-quality overall visuals.
      </h2>
    </div>
  </div>
</section>

<!-- End video carousel -->





<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <h2 class="title is-4">The results of the ablation experiments</h2>
      
      <div id="results-carousel" class="carousel results-carousel" style="height: 600px; margin: auto;">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/ablation/65_65_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/contrast/73_73_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">
            <source src="static/contrast/81_81_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="video4" autoplay controls muted loop height="100%">
            <source src="static/contrast/95_95_4videos_concat.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      
      <h2 class="content has-text-centered">
        Qualitative results compared with other methods. Our method achieves accurate gesture generation and high-quality overall visuals.
      </h2>
    </div>
  </div>
</section>

<!-- End video carousel -->

  




<footer class="footer" style="padding-top: 6px; padding-bottom: 6px;">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Our website template comes from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and is modified based on it. Thanks to the authors contribution.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body>
</html>
